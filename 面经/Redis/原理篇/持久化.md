# 持久化
Redis的数据全部在内存里，需要有一种机制来保证Redis的数据不会因为故障而丢失，这种就是Redis的持久化机制。

Redis的持久化机制分为两种，一种是快照，一种是AOF日志。快照是全量备份，AOF日志是连续的增量备份。快照是内存数据的二进制序列化形式，在存储上非常紧凑，而AOF日志记录的是内存数据修改的指令记录文本。

AOF日志在长期运行过程中会变得无比庞大，数据库重启时需要加载AOF日志进行指令重放，这个时间就会无比漫长，所以需要定期进行AOF重写，给AOF日志进行瘦身。

## 快照原理
持久化所面临的两个问题：
- 单线程在服务线上请求的同时，还要进行文件io操作，而文件IO操作会严重拖累服务器的性能
- 持久化的同时，线上请求还在不断改变着内存数据结构，该如何处理两者的矛盾。

对于第一问题，使用fork：

Redis在持久化时会调用glibc的函数fork产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。这是Linux操作系统的机制，为了节约内存资源，所以尽可能地让它们共享起来。在进程分离的一瞬间，内存的增长几乎没有明显变化。

```python
pid = os.fork()
if pid > 0: 
  handle_client_requests()      # 父进程继续处理客户端请求
if pid == 0:
  handle_snapshot_write()       # 子进程处理快照写磁盘
if pid < 0:                     # 操作系统内存资源不足fork失败
  # fork error
```

对于第二个问题，使用COW：

Redis使用操作系统的多进程COW（Copy On Write）机制来实现快照持久化。

数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面进行修改的时候，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这是子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。

子进程因为数据没有变化，能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么Redis的持久化叫”快照“的原因

## AOF原理
AOF日志存储的是Redis服务器的顺序指令序列，AOF日志只记录对内存进行修改的指令记录。

Redis会在收到客户端修改指令后，进行参数校验、逻辑处理，如果没问题，就立即将该指令文本存储到AOF日志中，也就是说，先执行指令才将日志存盘。

## AOF重写
Redis提供了bgrewriteaof指令用于对AOF日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历,转换成一系列Redis的操作指令，序列化到一个新的AOF日志文件中。序列化完毕后再将操作期间发生的增量AOF日志追加到这个新的AOF日志文件中，追加完毕后就立即替代旧的AOF日志文件了，瘦身工作完成了。

个人理解：

AOF日志中记录的指令非常繁杂，比如：
```java
> set w java
> get w
> set w python
> set w codehole
```
这几个指令可以合并成”set w codehole“，期间的读的指令完全可以忽略，因为它对数据并没有修改。这样省去了读的指令，并压缩了修改的指令，达到了瘦身。

## fsync
AOF日志是以文件的形式存在，当程序对AOF日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘。

Linux的glibc提供的fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁盘。

在生产服务器中，Redis通常是每隔1s左右执行一次fsync操作，这个1s周期可以配置。这是在数据安全性与性能之间做的一个折中。

## Redis混合持久化
Redis的rdb恢复状态会丢失大量数据，而使用AOF日志重放又太慢，这时候可以考虑将两者结合起来，形成混合持久化。

AOF日志不再是全量日志，而是自持久化开始到持久化结束的这段时间发生的增量AOF日志，通常这部分AOF日志很小。

Redis重启的时候可以先加载rdb的内容，然后再重放增量AOF日志，重启效率大幅提升。
