# 可靠性保证
了解系统的保证机制对于构建可靠的应用程序来说至关重要。

kafka可以在哪些方面做出保证：
- kafka可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入，那么Kafka可以保证消息B的偏移量比消息A的偏移量大。，而且消费者会先读取消息A再读取消息B。
- 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘）,它才被认为是“已提交的”。
- 只要还有一个副本时活跃的，那么已经提交的消息就不会丢失。
- 消费者只能读取已经提交的消息。

## 复制
Kafka的复制机制和分区的多副本架构是Kafka可靠性保证的核心。把消息写入多个副本可以使Kafka在发生崩溃时仍能保证消息的持久性。

Kafka的主题被分为多个分区，分区是基本的数据块。每个分区可以有多个副本，其中一个副本是首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其他副本只需要与首领保持同步，并及时复制最新的事件。

分区首领是同步副本，而对于跟随者来说，它需要满足以下条件才能被认为是同步的。
- 与Zookeeper之间有一个活跃的会话，也就是说，它在过去的6s内向Zookeeper发送过心跳
- 在过去的10s内从首领那里获取过消息
- 在过去的10s内从首领那里获取过最新的消息，光从首领那里获取消息是不够的，它还必须是几乎零延迟的。

## broker配置
broker有3个配置系数会影响Kafka消息存储的可靠性。

1.复制系数

如果复制系数是N，那么在N-1个broker失效的情况下，仍然能够从主题读取数据或向主题写入数据。更高的复制系数会带来更高的可用性、可靠性和更少的故障。另一方面，复制系数N需要至少N个broker，而且会有N个数据副本，也就是说它们会占用N倍的磁盘空间。

## 不完全的首领选举
unclean.leader.election参数是在broker范围，实际上是集群范围内的选举控制，默认是true。

不完全同步有两种情况：
- 分区有3个副本，其中两个出现了崩溃，而剩下的一个副本是同步的，此时生产者的消息可以被确认和提交，假设首领也不可用了，这个时候之前的一个跟随者又重新启动，就会出现不同步的情况。
- 分区内3个副本，因为网络问题导致两个副本是不同步的，也只有首领是同步的，此时如果首领出现了不可用的情况，那么数据也是不同步的。

此时有两种选择：
- 一种就是保证数据的同步，一致性。此时不同步的副本不能成为新首领，那么在分区首领重新恢复之前是不可用的。有时这种状态会持续数小时，这个在银行信用卡业务会严格要求。
- 一种就是保证可用性，但是会丢失数据。不同步的副本成为新首领，那么和之前分区首领不同步的数据就会丢失，部分消费者接收的是原首领的数据，部分消费者接收的是新首领的数据，甚至有消费者一部分是新首领的数据，一部分是原首领的数据，这就会导致数据的不准确。就算是原首领重新恢复，也会变成跟随者，会删除与新首领不一致的数据。

如果我们允许不同步的副本成为新首领，那么就要承担丢失数据和出现数据不一致的风险，而不允许不同步的副本成为新首领，就要接受较低的可用性，直到原首领恢复到可用状态。

## 最少同步副本
在主题和broker范围内，这个参数叫min.insync.replicas.

在不完全首领选举的情况下，就需要面临可用性和丢失数据的两难抉择。这时在实际使用中，设置最少同步副本可以解决这个问题。在确认已提交的时候判断是否满足最少同步副本数，如果满足才会认为是提交成功的，否则就是失败的。

