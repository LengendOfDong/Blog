# 高级应用

## 过期时间（TTL）

消息超时之后可以配合死信队列使用，这样被丢弃的消息可以被再次保存起来，方便应用在此之后通过消费死信队列中的消息来诊断系统的运行情况。

实现自定义每条消息的TTL功能，可以在沿用之前的timestamp字段和拦截器ConsumerInterceptor接口的onConsume()方法，还需要要消息中的headers字段来做配合。可以将消息的TTL设定值以键值对的形式保存在消息的headers中，这样消费者在消费到这条消息的时候可以在拦截器中根据headers字段中设定的超时时间来判断此条消息是否超时。

## 延时队列

延时队列存储的对象都是延时消息。所谓“延时消息”就是指消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取这个消息进行消费，延时队列一般也被称为“延迟队列”。

延时与TTL的区别：延时的消息达到目标延时的时间后才能被消费，而TTL的消息达到目标超时时间后会被丢弃。

延时队列的应用场景：

- 在订单系统中，一个用户下单之后通常有30分钟的时间进行支付，如果30分钟之内没有支付成功，那么这个订单将进行异常处理，这时就可以使用延时队列来处理这些订单。
- 订单完成1小时后通知用户进行评价
- 用户希望通过手机远程遥控家里的智能设备在指定时间进行工作。这时就可以将用户指令发送到延时队列，当指令设定的时间到了之后再将它推送到智能设备。

1.非精确处理延时消息的方案：

在发送延时消息的时候并不是先投递到发送的真实主题中，而是先投递到一些Kafka内部的主题中，这些内部主题对用户不可见，然后通过一个自定义的服务拉取这些内部主题中的消息，并将满足条件的消息再投递到要发送的真实的主题中，消费者所订阅的还是真实的主题。

总体实现：

在内部中，Producer会根据不同的延时时间将消息划分为不同的延时等级，然后根据所划分的延时等级再将消息发送到对应的内部主题中，比如5s内的消息发送到delay_topic_1,6s到10s的消息划分到delay_topic_2中。发送到内部主题（delay_topic_*）中的消息会被一个独立的DelayService进程消费，这个进程和Kafka broker进程以一对一的配比进行同机部署。

DelayService实现：

针对不同的延时级别的主题，在DelayService的内部都会有单独的线程来进行消息的拉取，以及单独的DelayQueue进行消息的暂存。与此同时，在DelayService中还会有专门的消息并转发到真实的主题中。DelayQueue的作用是将消息按照再次投递时间进行有序排序，这样下游的消息发送线程就能够按照先后顺序获取最先满足投递条件的消息。

2.精确延时消息方案：

每个时间格代表1秒，若要支持2小时之内的延时时间的消息，就需要整个单层时间轮的时间格数就需要7200个，与此对应的也就需要7200个文件。不过并不需要加载所有的文件，而是加载临近表盘指针位置的文件，整体上在内存中只需要维持少量的文件句柄就可以让系统运转起来。

单层时间轮对比多层时间轮的好处就在于不用考虑繁杂的锁机制。采用时间轮的方式解决了延时精度的问题，采用文件解决了内存暴涨的问题，至于可靠性的问题，生产者可以将消息写入多个备份中，待时间轮转动而触发某些时间格过期就可以将时间格对应的文件内容（也就是延时消息）转发到真实主题中，并且删除相应的文件，同时还有一个后台服务用来清理其他时间轮中相应的时间格。

## 死信队列和重试队列

死信队列：由于某些原因消息无法被正确地投递，为了确保消息不会被无故地丢弃，一般将其置于一个特殊角色的队列，这个队列一般称为死信队列。

重试队列其实可以看做是一种回退队列，具体指消费端消费消息失败时，为了防止消息无故丢失而重新将消息回滚到broker中。

重试队列与回退队列不同的是，重试队列一般分为多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大。设置上限后，超过投递上限就进入死信队列。

## 消息路由

在消息的headers字段中加入一个键为“routingkey"、值为特定业务标识的Header，然后在消费端中使用拦截器挑选出特定业务标识的消息。Kafka中消费组ConsumerGroup1根据指定的Header标识rk2和rk3来消费主题TopicA和TopicB中所有对应的消息而忽略Header标识为rk1的消息，消费组ConsumerGroup2正好相反。

## 消息轨迹

消息轨迹是指一条消息从生产者发出，经由broker存储，再到消费者消费的整个过程中，各个相关节点的状态、时间、地点等数据汇聚而成的完整链路信息。

消息轨迹保存到主题trace_topic之后，还需要通过一个专门的处理服务模块对消息轨迹进行索引和存储，方便有效地进行检索。在查询检索页面进行检索的时候可以根据具体的消息ID进行精确检索，也可以根据消息的Key、主题、发送接收时间来模糊检索。

## 消息中间件选型

1.功能维度

- 优先级队列：优先级队列不同于先进先出队列，优先级高的消息具备优先被消费的特权。
- 消费模式：消费模式分为推模式和拉模式。推模式是指broker主动推送消息至消费端，实时性较好，需要一定的流控机制来确保broker推送过来的消息不会压垮消费端。拉模式是指消费端主动向broker请求拉取消息，实时性较推模式差，可以根据自身的处理能力控制拉取的消息量。
- 广播模式：消息一般有两种传递模式：点对点（P2P）模式和发布/订阅模式。RabbitMQ是一种典型的点对点模式，而Kafka是一种典型的发布/订阅模式。RabbitMQ中可以通过设置交换器类型来实现发布/订阅模式。
- 回溯消费：一般消息在消费完成之后就被处理了，之后再也不能消费该条消息。消息回溯正好相反，是指消息在消费之后，还能消费之前被消费的消息。
- 消息堆积+持久化：流量削峰是消息中间件的一个非常重要的功能，这个功能得益于消息堆积能力。消息堆积分内存式堆积和磁盘式堆积。RabbitMQ是典型的内存式堆积，Kafka是一个典型的磁盘式堆积，所有的消息都存储在磁盘中。
- 消息过滤：消息过滤是指按照既定的过滤规则为下游用户提供指定类别的消息。以Kafka为例，完全可以将不同类别的消息发送至不同的主题中，由此可以实现某种意义上的消息过滤。kafka可以通过ConsumerInterceptor接口或者KafkaStreams的filter功能进行消息过滤。
- 多租户：也可以称为多重租赁技术，是一种软件架构技术，主要用来实现多用户的环境下公用相同的系统或者程序组件，并且仍可以确保各用户间数据的隔离性。RabbitMQ就能够支持多租户技术，每个租户表示一个vhost，其本质是一个独立的小型RabbitMQ服务器，又有自己独立的队列、交换器及绑定关系等，并且它拥有自己独立的权限。
- 多协议支持：为了让生产者和消费者都能理解所承载的信息，生产者需要如何构造信息，消费者需要知道如何解析消息，它们就需要按照一种统一的格式来描述消息，这种统一的格式称为消息协议。一般消息层面的协议有AMQP/MQTT/STOMP/XMPP等。
- 跨语言支持：消息中间件本身具有应用解耦的特性，如果能够进一步支持多客户端语言，那么就可以将此特性的效能扩大。跨语言的支持力度也可以从侧面反映出该中间件的流行程度。
- 流量控制：流量控制针对的是生产者和消费者之间的速度不匹配的问题。通常的流控方法有stop-and-wait,滑动窗口和令牌桶等。
- 消息顺序性：消息顺序性是指保证消息有序
- 消息幂等性：为了确保消息在生产者和消费者之间进行传输，一般有三种传输保障：At most once,至多一次，消息可能丢失，但绝不会重复；at least once，至少一次，消息绝不会丢失，但可能重复；Exactly once, 精确一次，每条消息肯定会被传输一次且仅一次。Kafka的幂等性是指单个生产者对于单分区单会话的冪等，而事务可以保证原子性地写入多个分区，这两个功能加起来可以让Kafka具有EOS(Exactly Once Semantic)的能力。

2.性能维度

性能和功能有的时候是相悖的，kafka在开启冪等及事务功能的时候会使其性能降低。

3.可靠性和可用性

分布式系统架构是一致性协议理论的应用实现，对消息可靠性和可用性而言可以追溯到消息中间件背后的一致性协议。Kafka采用的类似PacificA的一致性协议，通过ISR（In-Sync-Replica）来保证多副本之间的同步，并且支持强一致性语义（通过acks实现）。对应的RabbitMQ是通过镜像环形队列实现多副本及强一致性语义的。多副本可以保证在master节点宕机异常之后可以提升slave作为新的master而继续提供服务来保障可用性。

4.运维管理

运维管理可以细分成申请、审核、监控、告警、管理、容灾以及部署。

5.社区力度及生态发展

一种”流行“的消息中间件，更新力度大，很多问题都可以找到对应的答案，可以迅速修复出现的问题，另外可以顺应技术的快速发展来变更一些新的功能。

